
# 基础知识

## 消息队列
参考资料：https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md

### 作用
解耦，异步，削峰。在特殊场景下有其对应的好处。

### 缺点
- 系统可用性降低。系统引入的外部依赖越多，越容易出现问题。
- 系统复杂度提高。消息是否丢失？是否有重复消费？怎么确保消息传递的顺序性？
- 一致性问题。

### 对比
Kafka， ActiveMQ， RabbitMQ， RocketMQ

### 消息队列高可用性（解决缺点1）
这个问题在不同的MQ中，会有不同的解决方案。

#### ***RabbitMQ***
基于主从结构做高可用性（而非分布式）

##### 单机模式
demo级别，生产中不会使用这个模式

##### 普通集群（无高可用性）
多台机器上启动MQ，你创建的Queue只会放在一个RabbitMQ的实例上，但是每个实例都会同步queue的元数据。你所在的实例A如果需要向实例B中拉取数据（你掌握每个queue的元数据，你知道需要的数据位于B上），那么就A向B发送请求，获取数据之后再发送给消费者。

缺点在于：
- mq内部产生大量的数据传输。
- 可用性没有保障。存储queue的实例如果宕机，数据就丢失了。

这个集群是非常朴素的方式连接起来的，彼此之间实际上并没有什么关联，跟分布式没关系。消费者随机分配实例进行连接，则有实例间拉取数据的开销；消费者固定连接queue所在实例，则有单个实例性能瓶颈问题。

存放queue的实例宕机，若开启了消息持久化功能，则数据未必会丢，但是也得等到实例恢复了，才能继续拉取数据。

> 这个方案主要用来提高吞吐量，跟高可用性没有什么关系。

##### 镜像集群（高可用性）
镜像模式，顾名思义，queue的消息会存在于多个实例上。生产者发送的消息首先交个一个实例，然后同步到每个实例上。所以消费者无论连接到哪一个实例都可以直接获取到数据。这样就不怕某一个机器宕机了。数据总是能找到的。

缺点在于：
- 消息要同步到所有机器上，开销太大
- 不是分布式的，不能线性扩展你的queue。？？


#### ***Kafka***

- kafka的架构：分布式，由多个broker组成（节点）。创建一个topic，每个topic的数据可以被分成多个partition，每个partition存放数据的一部分，每个partition也可以存放在不同的broker上。从而，每个topic的数据是分散在多个机器上的。

##### Kafka的HA机制
> HA：High Availability

即复制品机制（replica）。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。所有的副本会选举一个leader出来，生产和消费都只和leader打交道，其他的follower相当于只负责备份的功能。这意味着不需要考虑follower的数据一致性问题，只需要leader负责保证他们相一致，但不需要即时的确保同步。Kafka会均匀地把所有的副本分布在不同的机器上，来提高容错性。

这样当某个broker宕机的时候，可以找这个broker中存储的partition对应的副本。如果这个broker包含某个partition的leader，那么就从它的follower中选择一个leader出来。

### 消息队列的幂等性（不重复消费）

> 重复消费不可怕，只需要确保幂等性

- 重复消费

Kafka会通过offset序号来记录消费者消费到哪一条数据了。消费过的offset会被提交和记录到zookeeper中。但如果提交失败，则可能会出现重复消费，导致有些数据重复读取了。

- 幂等性

即使得到了若干条重复的数据，我们可以在使用的时候确保不要发生重复使用的情况。
解决方案譬如：
1. 写库的时候，先根据主键查一下。
2. 写redis，redis本身是set，天然幂等性。
3. 生产者发送每条数据的时候，加一个全局唯一的id，每次消费的时候根据id去redis里面查一查。这样来确保不要重复处理相同的消息即可。
4. 基于数据库的唯一键约束来自动阻止重复数据的插入。

### 消息队列的可靠性（不丢失消息）

#### RabbitMQ
三种消息丢失的情况：消息传入过程中被生产者弄丢；RabbitMQ收到消息，还没被消费自己弄丢；消费者弄丢；

##### 生产者丢失
- 事务机制
使用事务功能，在发送数据之前开启RabbitMQ事务再发送消息。如果未被接收到，则生产者会异常报错，从而可以回滚事务，以重试。若收到了消息，则提交事务。

- confirm机制
每次写的消息分配一个唯一的id，成功写入会回传一个ack消息。如果没成功接收，会回调一个nack接口。如果长时间未接收到回调，可以重发。

- 区别

事务机制是同步的，提交一个事务之后会阻塞在那里。confirm机制是异步的，在接收到消息之后再异步回调这个接口，这期间不影响其他消息的收发。生产者一般都使用confirm机制。

##### RabbitMQ丢失
需要开启RabbitMQ的持久化，消息写入之后会持久化到磁盘中。唯一可能造成丢失的情况：持久化之前数据就丢失了。这个概率很小。
- 为了避免这个情况，可以结合confirm机制，只有消息被持久化之后，才回传ack消息。

两个步骤：
1. 创建queue的时候设置持久化，这会持久化queue的元数据；
2. 将消息设置为持久化，queue的内容会存储到磁盘上。

##### 消费端丢失
关闭RabbitMQ的自动ack，让自己在代码确保处理完数据之后，才发送ack。

### 消息的顺序性

#### RabbitMQ
##### 错误场景
生产者按顺序发送了若干条数据，压入RabbitMQ的同一个内存队列中，不同的消费者同时消费这个队列中的数据，但消费者完成消费的顺序和生产者存入的顺序不一致。

##### 解决方案
？没看懂

#### Kafka
##### 错误场景
消费者从partition中按照顺序取出来数据，但是之后可能会使用多个线程并发处理消息。多个线程并发的时候，顺序可能会错乱。

##### 解决方案
具有相同key的数据都存储到同一个内存queue中，对于N个线程，每个线程分别消费一个内存queue

### 消息队列的延时和失效问题，消息积压问题

### 消息队列的架构设计思路
- 可扩展性要好，所以要分布式，从而方便增加吞吐量和容量。参照Kafka，broker-topic-partition，如果现有资源不够用了，就给topic增加partition，做数据迁移，增加机器。
- 持久化存储。那么mq的数据要落盘。顺序落盘可以保证顺序读写，这样在取数据的时候就不用对磁盘内容进行随机访问。磁盘擅长顺序读写，这也是Kafka的思路。
- 可用性要好。仍然参照Kafka的思路，多个副本进行存储（冗余确保宕机不影响）-leader&follower的机制来方便生产者和消费者读写-leader宕机后重新选举。
- （卡夫卡牛逼！）

## RocketMQ的相关知识

参考资料：https://blog.csdn.net/qq_34462387/article/details/86562856

### 解耦
用消息队列作为中间件
- 订单系统向mq写入订单消息，就返回用户下单成功；
- 库存系统订阅mq中的订单消息，在进行相应的库存操作。

由是，加入在下单的时候库存系统不能正常使用，也不影响下单操作。我们只需要确保中间件的正常工作就可以了。库存系统可以在正常的时候去和消息队列进行交互，从而实现了解耦合。

> 想到一个疑问，如何确保一致性？在库存系统还未修改的时候，订单系统是否可以对同一个库存进行操作？

### 削峰
面对可能到来的流量突增活动（秒杀等），需要在应用前端增加消息队列。
- 用户请求写入mq；
- 秒杀业务处理系统根据规则从mq中读取请求，来进行后续的判断。

- 用户的请求服务器接收后，直接写入mq；如果超出了mq的容量，则抛弃请求或者跳转到错误界面（秒杀失败？）
  
### 消息模式
1. 点对点发布 两个客户端一一对应，互相收发，通过mq作为中间件
2. 发布-订阅模式

### 事务处理



# 开发者指南

中文文档：https://github.com/apache/rocketmq/tree/master/docs/cn





